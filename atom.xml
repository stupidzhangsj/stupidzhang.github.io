<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>stupidzhang</title>
  
  <subtitle>码农的世界，不仅仅只有coding...</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-07-11T06:13:45.500Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>stupidzhang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>如何优雅的实现分布式锁</title>
    <link href="http://yoursite.com/2019/07/11/%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
    <id>http://yoursite.com/2019/07/11/如何优雅的实现分布式锁/</id>
    <published>2019-07-11T06:12:07.000Z</published>
    <updated>2019-07-11T06:13:45.500Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h1><p><strong>写在前面</strong></p><p>很多大型网站及应用都是分布式部署的，分布式场景中的数据一致性问题一直是一个比较重要的话题。<br>分布式的 CAP 理论告诉我们“任何一个分布式系统都无法同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance），最多只能同时满足两项。”<br>所以，很多系统在设计之初就要对这三者做出取舍。在绝大多数的场景中，都需要牺牲强一致性来换取系统的高可用性，系统往往只需要保证“最终一致性”，只要这个最终时间是在用户可以接受的范围内即可。</p><p>在实现分布式锁之前，我们先想一想，我们需要的分布式锁是怎样的？</p><ul><li>保证在分布式部署的应用集群中，个方法在同一时间只能被一个线程执行。</li><li>这把锁要是一把可重入锁（避免死锁）；</li><li>这把锁最好是一把阻塞锁（根据业务需求考虑要不要这条）；</li><li>有高可用的获取锁和释放锁功能；</li><li>获取锁和释放锁的性能要好。</li></ul><p><strong>针对分布式锁的实现，目前比较常用的有以下几种方案：</strong></p><ul><li>基于数据库</li><li>基于缓存（redis，memcache等）</li><li>基于Zookeeper实现分布式锁</li></ul><p>这里我先说说基于数据库和缓存实现的方案。</p><a id="more"></a><h2 id="基于数据库实现分布式锁"><a href="#基于数据库实现分布式锁" class="headerlink" title="基于数据库实现分布式锁"></a>基于数据库实现分布式锁</h2><h3 id="基于数据库表"><a href="#基于数据库表" class="headerlink" title="基于数据库表"></a>基于数据库表</h3><p>用这种方式实现分布式锁，最简单的就是数据库中新建一张表，通过对这张表的操作来完成。<br>当我们需要锁住某种资源时，就往这张表中插入一条数据，记录锁住的资源名称，释放锁就删除这条数据；是不是很简单？</p><p>等等，有的同学就要提出质疑了。</p><blockquote><ol><li>这种锁对数据库的可用性具有强依赖，若数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用，当然这个问题在其他的方案也依然存在。</li><li>这种锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。</li><li>这种锁只能是非阻塞的，因为数据的insert操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。</li><li>这种锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。</li></ol></blockquote><p>当然，我们也可以有其他方式解决上面的问题。</p><blockquote><ol><li>数据库是单点？搞两个数据库，数据之前双向同步。一旦挂掉快速切换到备库上。</li><li>没有失效时间？开启一个定时任务，定时把数据库中的超时数据清理一遍。</li><li>非阻塞的？让它自旋，直到 insert 成功再返回成功。</li><li>非重入的？在数据库表中加个字段，记录当前获得锁的机器的主机信息和线程信息。查询时判断是否是否是自己上的锁即可。</li></ol></blockquote><p><strong>数据库实现分布式锁的优点</strong></p><pre><code>直接借助数据库，容易理解。</code></pre><p><strong>数据库实现分布式锁的缺点</strong></p><pre><code>1. 会有各种各样的问题，在解决问题的过程中会使整个方案变得越来越复杂。2. 操作数据库需要一定的开销，性能问题需要考虑。</code></pre><h3 id="基于数据库排他锁"><a href="#基于数据库排他锁" class="headerlink" title="基于数据库排他锁"></a>基于数据库排他锁</h3><p>排他锁实现方式基于是Mysql中 Innodb 引擎的行级锁，只要在查询锁语句后面增加 <code>for update</code>，<br>数据库会在查询过程中给数据库表增加排他锁。 注意的是：InnoDB引擎在加锁的时候，只有通过索引进行检索的时候才会使用行级锁，否则会使用表级锁。</p><p>这里我们希望使用行级锁，就要给锁信息添加索引。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">// 加锁</span><br><span class="line">public boolean lock()&#123;</span><br><span class="line">    connection.setAutoCommit(false)</span><br><span class="line">    while(true)&#123;</span><br><span class="line">            result = select();</span><br><span class="line">            if(result == null)&#123;</span><br><span class="line">                insert();</span><br><span class="line">                return true;</span><br><span class="line">            &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return false;</span><br><span class="line">&#125;</span><br><span class="line">// 释放锁</span><br><span class="line">public void unlock()&#123;</span><br><span class="line">    connection.commit();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这种方法可以有效的解决上面提到的无法释放锁和阻塞锁的问题。</p><ul><li>阻塞锁？ for update语句会在执行成功后立即返回，在执行失败时一直处于阻塞状态，直到成功。</li><li>锁定之后服务宕机，无法释放？使用这种方式，服务宕机之后数据库会自己把锁释放掉。</li></ul><hr><h2 id="基于缓存实现分布式锁"><a href="#基于缓存实现分布式锁" class="headerlink" title="基于缓存实现分布式锁"></a>基于缓存实现分布式锁</h2><p>相比较于基于数据库实现分布式锁的方案来说，基于缓存来实现在性能方面会表现的更好一点。</p><p>这里以 Redis 为例来介绍如何实现分布式锁</p><p>说到使用 redis 来实现分布式锁，读者可能第一时间就想到了<code>SETNX</code>命令,设置成功后可以通过 <code>EXPIRE</code> 设置锁的过期时间。<br>伪代码下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 加锁操作</span></span><br><span class="line"><span class="function"><span class="keyword">boolean</span> <span class="title">tryLock</span><span class="params">(String key, <span class="keyword">int</span> timeout)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (SETNX key <span class="string">"1"</span> == <span class="number">1</span>) &#123;</span><br><span class="line">    EXPIRE key timeout</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//删除锁</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">unlock</span><span class="params">(String key)</span> </span>&#123;</span><br><span class="line">  DEL key</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>细心的同学就该发现问题了，加锁操作和设置过期时间并不是原子性的，假如加锁之后还没来的及对锁设置过期时间，服务或者 Redis 服务宕机了，那这个锁岂不是一直存在。<br><del>但是<code>SETNX</code>又不支持添加过期时间操作</del>（低于<code>2.6.12</code>版本的不支持）。</p><p>在新版本的 Redis（2.6.12）已经支持相关操作，可以解决设置 <code>EXPIRE</code> 的问题看<a href="http://redisdoc.com/string/set.html#set" target="_blank" rel="noopener">这里</a></p><p>这里呢是以低版本开发为例。<br>我们可以向 Redis 服务器提交 Lua 脚本，让 Redis 服务器来执行一些较复杂的逻辑，而此脚本的提交对于客户端来说是相对原子性的。这恰好解决了我们的问题！</p><p>我们可以用一个这样的lua脚本来描述加锁的逻辑（关于脚本的提交命令和 Redis 的相关规则可以看<a href="https://redis.io/commands/eval" target="_blank" rel="noopener">这里</a>）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (redis.call(<span class="string">'setnx'</span>, KEYS[<span class="number">1</span>], ARGV[<span class="number">1</span>]) == <span class="number">1</span>) then</span><br><span class="line">    redis.call(<span class="string">'expire'</span>, KEYS[<span class="number">1</span>], ARGV[<span class="number">2</span>])</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span></span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>注意：此脚本中命令的执行并不是严格意义上的原子性，如果其中第二条指令EXPIRE执行失败，整个脚本执行会返回错误，但是第一条指令 <code>SETNX</code> 仍然是已经生效的！<br>不过此种情况基本可以认为是 Redis 服务器已经崩溃（除非是开发阶段就可以排除的参数错误之类的问题），那么锁的安全性就已经不是这里可以关注的点了。这里认为对客户端来说是相对原子性的就足够了。</p><p>看一下具体的实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> DefaultRedisScript&lt;Long&gt; <span class="title">lockScript</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        DefaultRedisScript&lt;Long&gt; defaultRedisScript = <span class="keyword">new</span> DefaultRedisScript&lt;&gt;();</span><br><span class="line">        defaultRedisScript.setResultType(Long.class);</span><br><span class="line">        defaultRedisScript.setScriptText(<span class="string">"if redis.call('setnx', KEYS[1]) == 1 then return redis.call"</span> +</span><br><span class="line">                <span class="string">"('pexpire', KEYS[1], ARGV[1]) else return 0 end"</span>);</span><br><span class="line">        <span class="keyword">return</span> defaultRedisScript;</span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">public</span> Boolean <span class="title">tryLock</span><span class="params">(String key, String timeout)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> result = redisTemplate.execute(lockScript(), Collections.singletonList(key), timeout);</span><br><span class="line">    <span class="keyword">return</span> result == <span class="number">1L</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>看了上面的实现突然发现，原来代码还可以这样写。</p><p>但是细心的同学还是会发现问题，可能会出现删除别人的锁，what?<br>例如：A服务器加锁，执行业务逻辑，很快执行完毕，进行解锁操作，解锁判断，OK，准备进行del()操作，此时CPU切换到执行别的操作了，<br>或者JVM虚拟机进行垃圾回收操作。这时候，key到了过期时间，B服务器执行获取到锁，执行业务逻辑，还没执行完成，A服务器复活，执行del()操作，删除key；<br>此时，A服务器上的锁，超时而被删除，B服务器加锁，A服务器将其删除；</p><p>解决此问题，我们在创建 RedisLock 对象时用本机时间戳和 UUID 来创建一个绝对唯一的 lockValue ，然后在加锁时存入此值，并在解锁前用GET取出值进行比较，如果匹配才做DEL。<br>这里依然需要用LUA脚本保证整个解锁过程的原子性。</p><p>对上述代码的LUA 脚本进行修改</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> DefaultRedisScript&lt;Long&gt; <span class="title">lockScript</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        ...</span><br><span class="line">        defaultRedisScript.setScriptText(<span class="string">"if redis.call('setnx', KEYS[1], ARGV[1]) == 1 then return redis.call"</span> +</span><br><span class="line">         <span class="string">"('pexpire', KEYS[1], ARGV[1]) else return 0 end"</span>);</span><br><span class="line">       ...</span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">public</span> Boolean <span class="title">tryLock</span><span class="params">(String key, String lockValue,String timeout)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> result = redisTemplate.execute(lockScript(), Collections.singletonList(key), lockValue,timeout);</span><br><span class="line">    <span class="keyword">return</span> result == <span class="number">1L</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过lua脚本，解决了 <code>解铃还须系铃人</code> 的问题，但是并没有解决由于A服务器执行时间过长，导致锁失效，从而使得B服务器获取到了锁，对同一个key执行了相同的逻辑。<br>笔者想到了两种方式。首先，需要确认的是，以上的情况发生概率很低，如果你的系统并发量不大，业务逻辑不复杂的话，基本上很难遇到这个误删除的问题，或者A、B服务器都对同一个key执行业务逻辑的问题。</p><ul><li>第一个解决办法，如果不影响数据的最终一致性，那逻辑重复执行就重复执行吧，不影响数据的一致性就行。但是，此解决办法有个前提条件，不影响数据的最终一致性。也就是接口满足幂等性。</li><li>第二个解决办法是:守护线程，当A服务器设置的锁要超时的时候，守护线程再对该锁进行续命，加血，延长存活时间。</li></ul><hr><center>![多学一点知识，就可以少些一行代码](https://www.github.com/ZhangShengJun93/picture/raw/master/markdown/picture/qrcode_for_gh_52f3263641d5_258.jpg)<center>多学一点知识，就可以少些一行代码</center></center>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;分布式锁&quot;&gt;&lt;a href=&quot;#分布式锁&quot; class=&quot;headerlink&quot; title=&quot;分布式锁&quot;&gt;&lt;/a&gt;分布式锁&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;写在前面&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;很多大型网站及应用都是分布式部署的，分布式场景中的数据一致性问题一直是一个比较重要的话题。&lt;br&gt;分布式的 CAP 理论告诉我们“任何一个分布式系统都无法同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance），最多只能同时满足两项。”&lt;br&gt;所以，很多系统在设计之初就要对这三者做出取舍。在绝大多数的场景中，都需要牺牲强一致性来换取系统的高可用性，系统往往只需要保证“最终一致性”，只要这个最终时间是在用户可以接受的范围内即可。&lt;/p&gt;
&lt;p&gt;在实现分布式锁之前，我们先想一想，我们需要的分布式锁是怎样的？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;保证在分布式部署的应用集群中，个方法在同一时间只能被一个线程执行。&lt;/li&gt;
&lt;li&gt;这把锁要是一把可重入锁（避免死锁）；&lt;/li&gt;
&lt;li&gt;这把锁最好是一把阻塞锁（根据业务需求考虑要不要这条）；&lt;/li&gt;
&lt;li&gt;有高可用的获取锁和释放锁功能；&lt;/li&gt;
&lt;li&gt;获取锁和释放锁的性能要好。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;针对分布式锁的实现，目前比较常用的有以下几种方案：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基于数据库&lt;/li&gt;
&lt;li&gt;基于缓存（redis，memcache等）&lt;/li&gt;
&lt;li&gt;基于Zookeeper实现分布式锁&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里我先说说基于数据库和缓存实现的方案。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>如何保证消息的可靠性传输</title>
    <link href="http://yoursite.com/2019/07/11/%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BC%A0%E8%BE%93/"/>
    <id>http://yoursite.com/2019/07/11/如何保证消息的可靠性传输/</id>
    <published>2019-07-11T06:10:37.000Z</published>
    <updated>2019-07-11T06:13:36.796Z</updated>
    
    <content type="html"><![CDATA[<hr><p>title: 如何保证消息的可靠性传输？<br>date: 2019-07-11 11:33:56</p><h2 id="tags"><a href="#tags" class="headerlink" title="tags:"></a>tags:</h2><h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><p>如何保证消息的可靠性传输？或者说，如何处理消息丢失的问题？</p><h2 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h2><p>这个是肯定的，用 MQ 有个基本原则，就是<strong>数据不能多一条，也不能少一条</strong>，不能多，就是前面说的重复消费和幂等性问题。不能少，就是说这数据别搞丢了。那这个问题你必须得考虑一下。</p><p>如果说你这个是用 MQ 来传递非常核心的消息，比如说计费、扣费的一些消息，那必须确保这个 MQ 传递过程中<strong>绝对不会把计费消息给弄丢</strong>。</p><h2 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h2><p>数据的丢失问题，可能出现在生产者、MQ、消费者中，咱们从 RabbitMQ 和 Kafka 分别来分析一下吧。</p><h3 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h3><p><img src="https://www.github.com/ZhangShengJun93/picture/raw/master/markdown/picture/1562579935480.png" alt="enter description here"></p><a id="more"></a><h4 id="生产者弄丢了数据"><a href="#生产者弄丢了数据" class="headerlink" title="生产者弄丢了数据"></a>生产者弄丢了数据</h4><p>生产者将数据发送到 RabbitMQ 的时候，可能数据就在半路给搞丢了，因为网络问题啥的，都有可能。</p><p>此时可以选择用 RabbitMQ 提供的事务功能，就是生产者<strong>发送数据之前</strong>开启 RabbitMQ 事务<code>channel.txSelect</code>，然后发送消息，如果消息没有成功被 RabbitMQ 接收到，那么生产者会收到异常报错，此时就可以回滚事务<code>channel.txRollback</code>，然后重试发送消息；如果收到了消息，那么可以提交事务<code>channel.txCommit</code>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 开启事务</span></span><br><span class="line">channel.txSelect</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// 这里发送消息</span></span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">    channel.txRollback</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 这里再次重发这条消息</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 提交事务</span></span><br><span class="line">channel.txCommit</span><br></pre></td></tr></table></figure><p>但是问题是，RabbitMQ 事务机制（同步）一搞，基本上<strong>吞吐量会下来，因为太耗性能</strong>。</p><p>所以一般来说，如果你要确保说写 RabbitMQ 的消息别丢，可以开启 <code>confirm</code> 模式，在生产者那里设置开启 <code>confirm</code> 模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 <code>ack</code> 消息，告诉你说这个消息 ok 了。如果 RabbitMQ 没能处理这个消息，会回调你的一个 <code>nack</code> 接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。</p><p>事务机制和 <code>confirm</code> 机制最大的不同在于，<strong>事务机制是同步的</strong>，你提交一个事务之后会<strong>阻塞</strong>在那儿，但是 <code>confirm</code> 机制是<strong>异步</strong>的，你发送个消息之后就可以发送下一个消息，然后那个消息 RabbitMQ 接收了之后会异步回调你的一个接口通知你这个消息接收到了。</p><p>所以一般在生产者这块<strong>避免数据丢失</strong>，都是用 <code>confirm</code> 机制的。</p><h4 id="RabbitMQ-弄丢了数据"><a href="#RabbitMQ-弄丢了数据" class="headerlink" title="RabbitMQ 弄丢了数据"></a>RabbitMQ 弄丢了数据</h4><p>就是 RabbitMQ 自己弄丢了数据，这个你必须<strong>开启 RabbitMQ 的持久化</strong>，就是消息写入之后会持久化到磁盘，哪怕是 RabbitMQ 自己挂了，<strong>恢复之后会自动读取之前存储的数据</strong>，一般数据不会丢。除非极其罕见的是，RabbitMQ 还没持久化，自己就挂了，<strong>可能导致少量数据丢失</strong>，但是这个概率较小。</p><p>设置持久化有<strong>两个步骤</strong>：</p><ul><li>创建 queue 的时候将其设置为持久化<br><br>这样就可以保证 RabbitMQ 持久化 queue 的元数据，但是它是不会持久化 queue 里的数据的。</li><li>第二个是发送消息的时候将消息的 <code>deliveryMode</code> 设置为 2<br><br>就是将消息设置为持久化的，此时 RabbitMQ 就会将消息持久化到磁盘上去。</li></ul><p>必须要同时设置这两个持久化才行，RabbitMQ 哪怕是挂了，再次重启，也会从磁盘上重启恢复 queue，恢复这个 queue 里的数据。</p><p>注意，哪怕是你给 RabbitMQ 开启了持久化机制，也有一种可能，就是这个消息写到了 RabbitMQ 中，但是还没来得及持久化到磁盘上，结果不巧，此时 RabbitMQ 挂了，就会导致内存里的一点点数据丢失。</p><p>所以，持久化可以跟生产者那边的 <code>confirm</code> 机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 <code>ack</code> 了，所以哪怕是在持久化到磁盘之前，RabbitMQ 挂了，数据丢了，生产者收不到 <code>ack</code>，你也是可以自己重发的。</p><h4 id="消费端弄丢了数据"><a href="#消费端弄丢了数据" class="headerlink" title="消费端弄丢了数据"></a>消费端弄丢了数据</h4><p>RabbitMQ 如果丢失了数据，主要是因为你消费的时候，<strong>刚消费到，还没处理，结果进程挂了</strong>，比如重启了，那么就尴尬了，RabbitMQ 认为你都消费了，这数据就丢了。</p><p>这个时候得用 RabbitMQ 提供的 <code>ack</code> 机制，简单来说，就是你必须关闭 RabbitMQ 的自动 <code>ack</code>，可以通过一个 api 来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里 <code>ack</code> 一把。这样的话，如果你还没处理完，不就没有 <code>ack</code> 了？那 RabbitMQ 就认为你还没处理完，这个时候 RabbitMQ 会把这个消费分配给别的 consumer 去处理，消息是不会丢的。</p><p><img src="https://www.github.com/ZhangShengJun93/picture/raw/master/markdown/picture/1562580054894.png" alt="enter description here"></p><h3 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h3><h4 id="消费端弄丢了数据-1"><a href="#消费端弄丢了数据-1" class="headerlink" title="消费端弄丢了数据"></a>消费端弄丢了数据</h4><p>唯一可能导致消费者弄丢数据的情况，就是说，你消费到了这个消息，然后消费者那边<strong>自动提交了 offset</strong>，让 Kafka 以为你已经消费好了这个消息，但其实你才刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢咯。</p><p>这不是跟 RabbitMQ 差不多吗，大家都知道 Kafka 会自动提交 offset，那么只要<strong>关闭自动提交</strong> offset，在处理完之后自己手动提交 offset，就可以保证数据不会丢。但是此时确实还是<strong>可能会有重复消费</strong>，比如你刚处理完，还没提交 offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。</p><p>生产环境碰到的一个问题，就是说我们的 Kafka 消费者消费到了数据之后是写到一个内存的 queue 里先缓冲一下，结果有的时候，你刚把消息写入内存 queue，然后消费者会自动提交 offset。然后此时我们重启了系统，就会导致内存 queue 里还没来得及处理的数据就丢失了。</p><h4 id="Kafka-弄丢了数据"><a href="#Kafka-弄丢了数据" class="headerlink" title="Kafka 弄丢了数据"></a>Kafka 弄丢了数据</h4><p>这块比较常见的一个场景，就是 Kafka 某个 broker 宕机，然后重新选举 partition 的 leader。大家想想，要是此时其他的 follower 刚好还有些数据没有同步，结果此时 leader 挂了，然后选举某个 follower 成 leader 之后，不就少了一些数据？这就丢了一些数据啊。</p><p>生产环境也遇到过，我们也是，之前 Kafka 的 leader 机器宕机了，将 follower 切换为 leader 之后，就会发现说这个数据就丢了。</p><p>所以此时一般是要求起码设置如下 4 个参数：</p><ul><li>给 topic 设置 <code>replication.factor</code> 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。</li><li>在 Kafka 服务端设置 <code>min.insync.replicas</code> 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 吧。</li><li>在 producer 端设置 <code>acks=all</code>：这个是要求每条数据，必须是<strong>写入所有 replica 之后，才能认为是写成功了</strong>。</li><li>在 producer 端设置 <code>retries=MAX</code>（很大很大很大的一个值，无限次重试的意思）：这个是<strong>要求一旦写入失败，就无限重试</strong>，卡在这里了。</li></ul><p>我们生产环境就是按照上述要求配置的，这样配置之后，至少在 Kafka broker 端就可以保证在 leader 所在 broker 发生故障，进行 leader 切换时，数据不会丢失。</p><h4 id="生产者会不会弄丢数据？"><a href="#生产者会不会弄丢数据？" class="headerlink" title="生产者会不会弄丢数据？"></a>生产者会不会弄丢数据？</h4><p>如果按照上述的思路设置了 <code>acks=all</code>，一定不会丢，要求是，你的 leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。</p><p><img src="https://www.github.com/ZhangShengJun93/picture/raw/master/markdown/picture/qrcode_for_gh_52f3263641d5_258.jpg" alt="多学一点知识，就可以少些一行代码"></p>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;title: 如何保证消息的可靠性传输？&lt;br&gt;date: 2019-07-11 11:33:56&lt;/p&gt;
&lt;h2 id=&quot;tags&quot;&gt;&lt;a href=&quot;#tags&quot; class=&quot;headerlink&quot; title=&quot;tags:&quot;&gt;&lt;/a&gt;tags:&lt;/h2&gt;&lt;h2 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h2&gt;&lt;p&gt;如何保证消息的可靠性传输？或者说，如何处理消息丢失的问题？&lt;/p&gt;
&lt;h2 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h2&gt;&lt;p&gt;这个是肯定的，用 MQ 有个基本原则，就是&lt;strong&gt;数据不能多一条，也不能少一条&lt;/strong&gt;，不能多，就是前面说的重复消费和幂等性问题。不能少，就是说这数据别搞丢了。那这个问题你必须得考虑一下。&lt;/p&gt;
&lt;p&gt;如果说你这个是用 MQ 来传递非常核心的消息，比如说计费、扣费的一些消息，那必须确保这个 MQ 传递过程中&lt;strong&gt;绝对不会把计费消息给弄丢&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&quot;面试题剖析&quot;&gt;&lt;a href=&quot;#面试题剖析&quot; class=&quot;headerlink&quot; title=&quot;面试题剖析&quot;&gt;&lt;/a&gt;面试题剖析&lt;/h2&gt;&lt;p&gt;数据的丢失问题，可能出现在生产者、MQ、消费者中，咱们从 RabbitMQ 和 Kafka 分别来分析一下吧。&lt;/p&gt;
&lt;h3 id=&quot;RabbitMQ&quot;&gt;&lt;a href=&quot;#RabbitMQ&quot; class=&quot;headerlink&quot; title=&quot;RabbitMQ&quot;&gt;&lt;/a&gt;RabbitMQ&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;https://www.github.com/ZhangShengJun93/picture/raw/master/markdown/picture/1562579935480.png&quot; alt=&quot;enter description here&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>为什么使用消息队列</title>
    <link href="http://yoursite.com/2019/07/11/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    <id>http://yoursite.com/2019/07/11/为什么使用消息队列/</id>
    <published>2019-07-11T03:23:30.000Z</published>
    <updated>2019-07-11T05:56:13.593Z</updated>
    
    <content type="html"><![CDATA[<h4 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h4><ul><li>为什么使用消息队列？</li><li>消息队列有什么优点和缺点？</li><li>Kafka、ActiveMQ、RabbitMQ、RocketMQ 都有什么区别，以及适合哪些场景？</li></ul><h4 id="面试官心理分析"><a href="#面试官心理分析" class="headerlink" title="面试官心理分析"></a>面试官心理分析</h4><p>其实面试官主要是想看看：</p><ul><li><p>第一，你知不知道你们系统里为什么要用消息队列这个东西？<br>不少候选人，说自己项目里用了 Redis、MQ，但是其实他并不知道自己为什么要用这个东西。其实说白了，就是为了用而用，或者是别人设计的架构，他从头到尾都没思考过。<br>没有对自己的架构问过为什么的人，一定是平时没有思考的人，面试官对这类候选人印象通常很不好。因为面试官担心你进了团队之后只会木头木脑的干呆活儿，不会自己思考。</p></li><li><p>第二，你既然用了消息队列这个东西，你知不知道用了有什么好处&amp;坏处？<br>你要是没考虑过这个，那你盲目弄个 MQ 进系统里，后面出了问题你是不是就自己溜了给公司留坑？你要是没考虑过引入一个技术可能存在的弊端和风险，面试官把这类候选人招进来了，基本可能就是挖坑型选手。就怕你干 1 年挖一堆坑，自己跳槽了，给公司留下无穷后患。</p></li><li><p>第三，既然你用了 MQ，可能是某一种 MQ，那么你当时做没做过调研？<br>你别傻乎乎的自己拍脑袋看个人喜好就瞎用了一个 MQ，比如 Kafka，甚至都从没调研过业界流行的 MQ 到底有哪几种。每一个 MQ 的优点和缺点是什么。每一个 MQ 没有绝对的好坏，但是就是看用在哪个场景可以扬长避短，利用其优势，规避其劣势。<br>如果是一个不考虑技术选型的候选人招进了团队，leader 交给他一个任务，去设计个什么系统，他在里面用一些技术，可能都没考虑过选型，最后选的技术可能并不一定合适，一样是留坑。</p></li></ul><h4 id="面试题剖析"><a href="#面试题剖析" class="headerlink" title="面试题剖析"></a>面试题剖析</h4><p><strong>为什么使用消息队列</strong><br>其实就是问问你消息队列都有哪些使用场景，然后你项目里具体是什么场景，说说你在这个场景里用消息队列是什么？</p><p>面试官问你这个问题，期望的一个回答是说，你们公司有个什么业务场景，这个业务场景有个什么技术挑战，如果不用 MQ 可能会很麻烦，但是你现在用了 MQ 之后带给了你很多的好处。</p><p>先说一下消息队列常见的使用场景吧，其实场景有很多，但是比较核心的有 3 个：解耦、异步、削峰。</p><a id="more"></a><h4 id="解耦"><a href="#解耦" class="headerlink" title="解耦"></a>解耦</h4><p>看这么个场景。A 系统发送数据到 BCD 三个系统，通过接口调用发送。如果 E 系统也要这个数据呢？那如果 C 系统现在不需要了呢？A 系统负责人几乎崩溃……</p><p><img src="https://www.github.com/ZhangShengJun93/picture/raw/master/markdown/picture/1562577369332.png" alt="enter description here"></p><p>在这个场景中，A 系统跟其它各种乱七八糟的系统严重耦合，A 系统产生一条比较关键的数据，很多系统都需要 A 系统将这个数据发送过来。A 系统要时时刻刻考虑 BCDE 四个系统如果挂了该咋办？要不要重发，要不要把消息存起来？头发都白了啊！</p><p>如果使用 MQ，A 系统产生一条数据，发送到 MQ 里面去，哪个系统需要数据自己去 MQ 里面消费。如果新系统需要数据，直接从 MQ 里消费即可；如果某个系统不需要这条数据了，就取消对 MQ 消息的消费即可。这样下来，A 系统压根儿不需要去考虑要给谁发送数据，不需要维护这个代码，也不需要考虑人家是否调用成功、失败超时等情况。</p><p><img src="https://www.github.com/ZhangShengJun93/picture/raw/master/markdown/picture/1562577395252.png" alt="enter description here"></p><p>总结：通过一个 MQ，Pub/Sub 发布订阅消息这么一个模型，A 系统就跟其它系统彻底解耦了。</p><p>面试技巧：你需要去考虑一下你负责的系统中是否有类似的场景，就是一个系统或者一个模块，调用了多个系统或者模块，互相之间的调用很复杂，维护起来很麻烦。但是其实这个调用是不需要直接同步调用接口的，如果用 MQ 给它异步化解耦，也是可以的，你就需要去考虑在你的项目里，是不是可以运用这个 MQ 去进行系统的解耦。在简历中体现出来这块东西，用 MQ 作解耦。</p><h4 id="异步"><a href="#异步" class="headerlink" title="异步"></a>异步</h4><p>再来看一个场景，A 系统接收一个请求，需要在自己本地写库，还需要在 BCD 三个系统写库，自己本地写库要 3ms，BCD 三个系统分别写库要 300ms、450ms、200ms。最终请求总延时是 3 + 300 + 450 + 200 = 953ms，接近 1s，用户感觉搞个什么东西，慢死了慢死了。用户通过浏览器发起请求，等待个 1s，这几乎是不可接受的。</p><p><img src="https://www.github.com/ZhangShengJun93/picture/raw/master/markdown/picture/1562577412980.png" alt="enter description here"></p><p>一般互联网类的企业，对于用户直接的操作，一般要求是每个请求都必须在 200 ms 以内完成，对用户几乎是无感知的。</p><p>如果使用 MQ，那么 A 系统连续发送 3 条消息到 MQ 队列中，假如耗时 5ms，A 系统从接受一个请求到返回响应给用户，总时长是 3 + 5 = 8ms，对于用户而言，其实感觉上就是点个按钮，8ms 以后就直接返回了，爽！网站做得真好，真快！</p><p><img src="https://www.github.com/ZhangShengJun93/picture/raw/master/markdown/picture/1562577428681.png" alt="enter description here"></p><h4 id="削峰"><a href="#削峰" class="headerlink" title="削峰"></a>削峰</h4><p>每天 0:00 到 12:00，A 系统风平浪静，每秒并发请求数量就 50 个。结果每次一到 12:00 ~ 13:00 ，每秒并发请求数量突然会暴增到 5k+ 条。但是系统是直接基于 MySQL 的，大量的请求涌入 MySQL，每秒钟对 MySQL 执行约 5k 条 SQL。</p><p>一般的 MySQL，扛到每秒 2k 个请求就差不多了，如果每秒请求到 5k 的话，可能就直接把 MySQL 给打死了，导致系统崩溃，用户也就没法再使用系统了。</p><p>但是高峰期一过，到了下午的时候，就成了低峰期，可能也就 1w 的用户同时在网站上操作，每秒中的请求数量可能也就 50 个请求，对整个系统几乎没有任何的压力。</p><p><img src="https://www.github.com/ZhangShengJun93/picture/raw/master/markdown/picture/1562577465642.png" alt="enter description here"></p><p>如果使用 MQ，每秒 5k 个请求写入 MQ，A 系统每秒钟最多处理 2k 个请求，因为 MySQL 每秒钟最多处理 2k 个。A 系统从 MQ 中慢慢拉取请求，每秒钟就拉取 2k 个请求，不要超过自己每秒能处理的最大请求数量就 ok，这样下来，哪怕是高峰期的时候，A 系统也绝对不会挂掉。而 MQ 每秒钟 5k 个请求进来，就 2k 个请求出去，结果就导致在中午高峰期（1 个小时），可能有几十万甚至几百万的请求积压在 MQ 中。</p><p><img src="https://www.github.com/ZhangShengJun93/picture/raw/master/markdown/picture/1562577478496.png" alt="enter description here"></p><p>这个短暂的高峰期积压是 ok 的，因为高峰期过了之后，每秒钟就 50 个请求进 MQ，但是 A 系统依然会按照每秒 2k 个请求的速度在处理。所以说，只要高峰期一过，A 系统就会快速将积压的消息给解决掉。</p><p>消息队列有什么优缺点<br>优点上面已经说了，就是在特殊场景下有其对应的好处，解耦、异步、削峰。</p><p>缺点有以下几个：</p><p>系统可用性降低<br>系统引入的外部依赖越多，越容易挂掉。本来你就是 A 系统调用 BCD 三个系统的接口就好了，人 ABCD 四个系统好好的，没啥问题，你偏加个 MQ 进来，万一 MQ 挂了咋整，MQ 一挂，整套系统崩溃的，你不就完了？如何保证消息队列的高可用，可以点击这里查看。</p><p>系统复杂度提高<br>硬生生加个 MQ 进来，你怎么保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性？头大头大，问题一大堆，痛苦不已。</p><p>一致性问题<br>A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致了。</p><p>所以消息队列实际是一种非常复杂的架构，你引入它有很多好处，但是也得针对它带来的坏处做各种额外的技术方案和架构来规避掉，做好之后，你会发现，妈呀，系统复杂度提升了一个数量级，也许是复杂了 10 倍。但是关键时刻，用，还是得用的。</p><p>Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？<br>特性    ActiveMQ    RabbitMQ    RocketMQ    Kafka<br>单机吞吐量    万级，比 RocketMQ、Kafka 低一个数量级    同 ActiveMQ    10 万级，支撑高吞吐    10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景<br>topic 数量对吞吐量的影响    </p><p>topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic    topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源<br>时效性    ms 级    微秒级，这是 RabbitMQ 的一大特点，延迟最低    ms 级    延迟在 ms 级以内<br>可用性    高，基于主从架构实现高可用    同 ActiveMQ    非常高，分布式架构    非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用<br>消息可靠性    有较低的概率丢失数据    基本不丢    经过参数优化配置，可以做到 0 丢失    同 RocketMQ<br>功能支持    MQ 领域的功能极其完备    基于 erlang 开发，并发能力很强，性能极好，延时很低    MQ 功能较为完善，还是分布式的，扩展性好    功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用<br>综上，各种对比之后，有如下建议：</p><p>一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了；</p><p>后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高；</p><p>不过现在确实越来越多的公司会去用 RocketMQ，确实很不错，毕竟是阿里出品，但社区可能有突然黄掉的风险（目前 RocketMQ 已捐给 Apache，但 GitHub 上的活跃度其实不算高）对自己公司技术实力有绝对自信的，推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，人家有活跃的开源社区，绝对不会黄。</p><p>所以中小型公司，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；大型公司，基础架构研发实力较强，用 RocketMQ 是很好的选择。</p><p>如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。</p><p><img src="https://www.github.com/ZhangShengJun93/picture/raw/master/markdown/picture/qrcode_for_gh_52f3263641d5_258.jpg" alt="多学一点知识，就可以少些一行代码"></p>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;面试题&quot;&gt;&lt;a href=&quot;#面试题&quot; class=&quot;headerlink&quot; title=&quot;面试题&quot;&gt;&lt;/a&gt;面试题&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;为什么使用消息队列？&lt;/li&gt;
&lt;li&gt;消息队列有什么优点和缺点？&lt;/li&gt;
&lt;li&gt;Kafka、ActiveMQ、RabbitMQ、RocketMQ 都有什么区别，以及适合哪些场景？&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;面试官心理分析&quot;&gt;&lt;a href=&quot;#面试官心理分析&quot; class=&quot;headerlink&quot; title=&quot;面试官心理分析&quot;&gt;&lt;/a&gt;面试官心理分析&lt;/h4&gt;&lt;p&gt;其实面试官主要是想看看：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;第一，你知不知道你们系统里为什么要用消息队列这个东西？&lt;br&gt;不少候选人，说自己项目里用了 Redis、MQ，但是其实他并不知道自己为什么要用这个东西。其实说白了，就是为了用而用，或者是别人设计的架构，他从头到尾都没思考过。&lt;br&gt;没有对自己的架构问过为什么的人，一定是平时没有思考的人，面试官对这类候选人印象通常很不好。因为面试官担心你进了团队之后只会木头木脑的干呆活儿，不会自己思考。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;第二，你既然用了消息队列这个东西，你知不知道用了有什么好处&amp;amp;坏处？&lt;br&gt;你要是没考虑过这个，那你盲目弄个 MQ 进系统里，后面出了问题你是不是就自己溜了给公司留坑？你要是没考虑过引入一个技术可能存在的弊端和风险，面试官把这类候选人招进来了，基本可能就是挖坑型选手。就怕你干 1 年挖一堆坑，自己跳槽了，给公司留下无穷后患。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;第三，既然你用了 MQ，可能是某一种 MQ，那么你当时做没做过调研？&lt;br&gt;你别傻乎乎的自己拍脑袋看个人喜好就瞎用了一个 MQ，比如 Kafka，甚至都从没调研过业界流行的 MQ 到底有哪几种。每一个 MQ 的优点和缺点是什么。每一个 MQ 没有绝对的好坏，但是就是看用在哪个场景可以扬长避短，利用其优势，规避其劣势。&lt;br&gt;如果是一个不考虑技术选型的候选人招进了团队，leader 交给他一个任务，去设计个什么系统，他在里面用一些技术，可能都没考虑过选型，最后选的技术可能并不一定合适，一样是留坑。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;面试题剖析&quot;&gt;&lt;a href=&quot;#面试题剖析&quot; class=&quot;headerlink&quot; title=&quot;面试题剖析&quot;&gt;&lt;/a&gt;面试题剖析&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;为什么使用消息队列&lt;/strong&gt;&lt;br&gt;其实就是问问你消息队列都有哪些使用场景，然后你项目里具体是什么场景，说说你在这个场景里用消息队列是什么？&lt;/p&gt;
&lt;p&gt;面试官问你这个问题，期望的一个回答是说，你们公司有个什么业务场景，这个业务场景有个什么技术挑战，如果不用 MQ 可能会很麻烦，但是你现在用了 MQ 之后带给了你很多的好处。&lt;/p&gt;
&lt;p&gt;先说一下消息队列常见的使用场景吧，其实场景有很多，但是比较核心的有 3 个：解耦、异步、削峰。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
</feed>
